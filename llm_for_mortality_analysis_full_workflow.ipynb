{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fde60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "API_KEY_REF = \"YOUR_API_KEY_HERE\" # place your API key here\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY_REF}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "PDF_PATH = \"ILEC Mortality Report.pdf\"\n",
    "DATA_DICTIONARY_PATH = \"ILEC 2012_19 - Data Dictionary clean.csv\"\n",
    "DATA_SAMPLE_PATH = \"ILEC_Sample.csv\"\n",
    "\n",
    "def encode_to_base64(filepath):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Encode an arbitrary file (e.g. PDF, image) so that it can be passed as input to an LLM through a POST request\n",
    "\n",
    "    Arguments:\n",
    "        filepath (str): path to the file to be encoded\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def make_prompt_with_data_dict_and_sample(prompt, data_dict_path, sample_csv_path=None):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Return a string starting with a text representation of the provided data dictionary and sample csv file, along with user-provided prompt. Used for convenience across several types of LLM requests\n",
    "\n",
    "    Arguments:\n",
    "        prompt (str): prompt that will appear at the end of the user's request\n",
    "        data_dict_path (str): path to a csv file containing the data dictionary\n",
    "        sample_csv_path (str): path to a csv file containing a handful of records from the dataset\n",
    "    \"\"\"\n",
    "    output = \"ILEC_Mortality_Table Data Dictionary:\\n\\n\"\n",
    "    with open(data_dict_path, \"r\") as f:\n",
    "        output += \"\".join(f.readlines())\n",
    "    if sample_csv_path is not None:\n",
    "        output += \"\\n\\nSample data from ILEC_Mortality_Table:\\n\\n\"\n",
    "        with open(sample_csv_path, \"r\") as f:\n",
    "            for i in range(5): # load up to the first five lines of the file\n",
    "                new_line = f.readline()\n",
    "                if new_line:\n",
    "                    output += new_line\n",
    "                else:\n",
    "                    break\n",
    "    return output + \"\\nTask:\\n\" + prompt\n",
    "\n",
    "def get_initial_ideas(model_name, structure_path, output_file=None):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Request a list of ideas from a model based on report PDF and data. Log the results.\n",
    "    Note: this function contains some hardcoded details (PDF file for retrieval)\n",
    "\n",
    "    Arguments:\n",
    "        model_name (str): specify the model to be used\n",
    "        structure_path (str): path to JSON file with the desired \"structure output\" that the LLM should follow\n",
    "        output_file (str): path to save output of LLM response (JSON)\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"I've provided an insurance mortality report with findings based on 2012 to 2019 data. I've also provided a data dictionary and a small data extract. Based on the report, identify several new ideas for how we can extend the analysis using only the data provided (e.g. additional cuts/segmentations). In your description, tie in your extension idea to the paper (e.g. your inspiration) and make sure that your suggested view is not already provided in the paper. You should list relevant dimensions of the cut. You MUST use observation_year, since we want to detect shifting trends over time. If the idea requires any filtering, please justify that choice in the response as well. We are only interested in actual vs expected trends (specifically, ratio of actual amount to expected amount) or mix shifts across the observation years (2012 through 2019) for segments to see how patterns are changing over time. The test should be designed so that we can identify trends based on a single graph. Note that if there are too many unique values for a dimension, we would not easily be able to compare trends, so in cases of 6 or more unique values (per the data dictionary), we must either filter to a smaller list or group values together. For each of your extension ideas, propose a hypothesis and what new trend insights we expect to learn from your proposed view. Try to come up with at least 4 ideas.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": make_prompt_with_data_dict_and_sample(prompt, DATA_DICTIONARY_PATH, DATA_SAMPLE_PATH)\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"file\",\n",
    "                    \"file\": {\n",
    "                        \"filename\": PDF_PATH,\n",
    "                        \"file_data\": f\"data:application/pdf;base64,{encode_to_base64(PDF_PATH)}\"\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    plugins = [{\"id\": \"file-parser\",\"pdf\": {\"engine\": \"pdf-text\"}}]\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"idea_list\",\n",
    "                \"strict\": True,\n",
    "                \"schema\": json.load(open(structure_path, \"r\"))\n",
    "            }\n",
    "        },\n",
    "        \"require_parameters\": True,\n",
    "        \"plugins\": plugins\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(OPENROUTER_URL, headers=HEADERS, json=payload)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API request: {e}\")\n",
    "    if output_file is None:\n",
    "        curr_timestamp = datetime.datetime.now().isoformat()[:-7]\n",
    "        output_file = f\"ideas_response_{curr_timestamp.replace(':', '')}.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "    print(f\"Successfully evaluated initial ideas!\")\n",
    "    return response.json()\n",
    "\n",
    "def get_sql_code(model_name, query_request, query_structure_path, save_query_file):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Make a request to an LLM to generate a SQL query based on the provided information, conforming to the template specified\n",
    "\n",
    "    Arguments:\n",
    "        model_name (str): specify the model to be used\n",
    "        query_request (dict):cContains details of the goal/purpose to help the LLM generate an appropriate SQL query\n",
    "        query_structure_path (str): path to a JSON file with a specified structured output\n",
    "        save_query_file (str): path to a file indicating where to save the provided query\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Write a SQL query based on the following overview in order to test the hypothesis. The general intent is to identify actual vs expected trends (actual/ratio is supposed to be a ratio) or mix shifts across the observation years (2012 to 2019) for segments to see how patterns are changing over time. The table to use is called ILEC_Mortality_Table. If the query creates an actual vs expected column, it should be called AE_Ratio_Amount. If the query creates a mix percentage column, it should be called Mix_Percentage. Pay attention to the datatypes listed in the data dictionary - avoid using CAST to change datatypes. Additionally, identify all the segment columns (e.g. Observation_Year) for which we'll look at trends. You should reason through how the query answers the request mentioned in the Request and Hypothesis section.\\n\\nRequest:\\n{query_request['overview']}\\n\\nHypothesis:\\n{query_request['hypothesis']}\\n\\nPossible Fields:\\n{query_request['dimensions']}\"\"\" + (f\"\\n\\nPossible Filters:\\n{query_request['filters']}\" if \"filters\" in query_request.keys() else \"\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": make_prompt_with_data_dict_and_sample(prompt, DATA_DICTIONARY_PATH, DATA_SAMPLE_PATH)\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages,\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"sql_info\",\n",
    "                \"strict\": True,\n",
    "                \"schema\": json.load(open(query_structure_path, \"r\"))\n",
    "            }\n",
    "        },\n",
    "        \"require_parameters\": True\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OPENROUTER_URL, headers=HEADERS, json=payload)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API request: {e}\")\n",
    "    with open(save_query_file, \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "    print(f\"Successfully evaluated!\")\n",
    "    return response.json()\n",
    "\n",
    "def get_all_sql_code(model_name, idea_response_file, query_structure_path, output_file):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Send a request to specified LLM to generate a SQL query for each idea passed in\n",
    "\n",
    "    Arguments:\n",
    "        model_name (str): specify the model to be used\n",
    "        idea_response_file (str): path to JSON file containing LLM's ideas\n",
    "        query_structure_path (str): path to a JSON file with a specified structured output\n",
    "        output_file (str): path to JSON file indicating where to save the query's full details\n",
    "    \"\"\"\n",
    "    output_data = []\n",
    "    with open(idea_response_file, \"r\") as f:\n",
    "        idea_response = json.load(f)\n",
    "        ideas = json.loads(idea_response[\"choices\"][0][\"message\"][\"content\"])[\"ideas\"]\n",
    "    for i, idea_obj in enumerate(ideas):\n",
    "        print(f\"Processing {i+1} out of {len(ideas)}\")\n",
    "        curr_timestamp = datetime.datetime.now().isoformat()[:-7]\n",
    "        random_file_name = f\"response_{curr_timestamp.replace(':', '')}.json\"\n",
    "        res = get_sql_code(model_name, idea_obj, query_structure_path, random_file_name)\n",
    "        sql_content = json.loads(res[\"choices\"][0][\"message\"][\"content\"])\n",
    "        output_data.append({\n",
    "            \"json_request_location\": random_file_name,\n",
    "            \"overview\": idea_obj[\"overview\"],\n",
    "            \"hypothesis\": idea_obj[\"hypothesis\"],\n",
    "            \"dimensions\": idea_obj[\"dimensions\"],\n",
    "            \"filters\": idea_obj.get(\"filters\", \"\"),\n",
    "            \"group_column_list\": sql_content[\"group_column_list\"],\n",
    "            \"sql_desc\": sql_content[\"description\"],\n",
    "            \"sql_code\": sql_content[\"sql_code\"]\n",
    "        })\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "    #print('Done!')\n",
    "    return output_data\n",
    "\n",
    "def exec_query(sql_query, save_location):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Clean up the provided SQL query and save it to the specified location\n",
    "\n",
    "    Arguments:\n",
    "        sql_query (str): SQL query, created by an LLM\n",
    "        save_location (str): path to a CSV file where the output data should be saved\n",
    "    \"\"\"\n",
    "    sql_query = sql_query.strip()\n",
    "    if not sql_query.lower().startswith(\"select\") and not sql_query.lower().startswith(\"with\"):\n",
    "        #print(sql_query)\n",
    "        raise ValueError(\"Malformed query: query does not start with 'select' or 'with'\")\n",
    "    sql_query = sql_query.replace('\"', \"'\") # replace with single quotes because duckdb is weird\n",
    "    if re.search(r'\\silec_mortality_table(\\s|;)', sql_query, flags=re.IGNORECASE):\n",
    "        sql_query = re.sub(r'ilec_mortality_table', \"read_csv_auto('ILEC_2012_19 - 20240429.txt', delim='\\t', types={'Age_Ind': 'VARCHAR', 'Preferred_Indicator': 'VARCHAR', 'Number_of_Pfd_Classes': 'VARCHAR', 'Preferred_Class': 'VARCHAR'})\", sql_query, flags=re.IGNORECASE)\n",
    "    else:\n",
    "        raise ValueError(\"Malformed query: could not find 'ilec_mortality_table' in query\")\n",
    "    if sql_query.endswith(\";\"):\n",
    "        sql_query = sql_query[:-1]\n",
    "    duckdb.sql(f\"\"\"COPY ({sql_query}) TO '{save_location}';\"\"\")\n",
    "\n",
    "def make_graph(data_path, query_detail):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Plots the data provided and saves it to the specified location\n",
    "\n",
    "    Arguments:\n",
    "        data_path (str): path to where the csv dataset is saved\n",
    "        query_info (dict): JSON object containing supplemental query information as additional context\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    \n",
    "    # Identify segment columns (everything that isn't the year or a numeric metric)\n",
    "    metrics = [\"total_actual_death_amount\", \"total_expected_death_amount\", \"ae_ratio_amount\", \"mix_percentage\"]\n",
    "    # try to figure out what the primary metric is:\n",
    "    if \"ae_ratio_amount\" in df.columns:\n",
    "        final_metric_col = \"ae_ratio_amount\"\n",
    "    elif \"mix_percentage\" in df.columns:\n",
    "        final_metric_col = \"mix_percentage\"\n",
    "    else:\n",
    "        final_metric_col = df.columns[-1]\n",
    "    #segment_cols = [c for c in df.columns if c != \"observation_year\" and c not in metrics and c != final_metric_col]\n",
    "    segment_cols = [col.lower() for col in query_detail[\"group_column_list\"] if col.lower() != \"observation_year\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Group by the list of segment columns\n",
    "    for keys, group in df.groupby(segment_cols):\n",
    "        # Create a label by joining segment values (handles one or multiple segments)\n",
    "        label = \" | \".join(map(str, keys)) if isinstance(keys, tuple) else str(keys)\n",
    "        \n",
    "        # Sort by year to ensure lines connect correctly\n",
    "        group = group.sort_values(\"observation_year\")\n",
    "        plt.plot(group[\"observation_year\"], group[final_metric_col], marker=\"o\", label=label)\n",
    "\n",
    "    plt.xlabel(\"Observation Year\")\n",
    "    plt.ylabel(final_metric_col)\n",
    "    plt.title(f\"{final_metric_col} by ({segment_cols})\")\n",
    "    plt.legend(title=\"Segments\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(query_detail[\"graph_data_path\"])\n",
    "    #plt.show()\n",
    "\n",
    "def query_data(all_queries_path, output_path):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Execute each query in provided JSON file and make a line graph based on the query's csv output. Save results in another JSON object\n",
    "\n",
    "    Arguments:\n",
    "        all_queries_path (str): path to JSON file with information regarding all queries\n",
    "        output_path (str): path to JSON file with additional information for all given queries\n",
    "    \"\"\"\n",
    "    with open(all_queries_path, \"r\") as f:\n",
    "        all_queries = json.load(f)\n",
    "    save_results = []\n",
    "    for i, query_obj in enumerate(all_queries):\n",
    "        print(f\"Executing query #{i+1}\")\n",
    "        curr_timestamp = datetime.datetime.now().isoformat()[:-7]\n",
    "        random_file_name = f\"agg_data_{curr_timestamp.replace(':', '')}.csv\"\n",
    "        query_obj[\"csv_data_path\"] = random_file_name\n",
    "        query_obj[\"graph_data_path\"] = f\"graph_{curr_timestamp.replace(':', '')}.jpeg\"\n",
    "        try:\n",
    "            exec_query(query_obj[\"sql_code\"], random_file_name)\n",
    "            query_obj[\"calc_status\"] = \"Success\"\n",
    "        except Exception as e:\n",
    "            query_obj[\"calc_status\"] = f\"Failure: {e}\"\n",
    "            query_obj[\"graph_status\"] = f\"Failure: cannot make graph due to failed csv creation\"\n",
    "        if query_obj[\"calc_status\"] == \"Success\":\n",
    "            try:\n",
    "                #make_graph(random_file_name, query_obj[\"graph_data_path\"])\n",
    "                make_graph(random_file_name, query_obj)\n",
    "                query_obj[\"graph_status\"] = \"Success\"\n",
    "            except Exception as e:\n",
    "                query_obj[\"graph_status\"] = f\"Failure: {e}\"\n",
    "        save_results.append(query_obj)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(save_results, f, indent=4)\n",
    "    return save_results\n",
    "\n",
    "def get_llm_graph_insights(model_name, query_details, output_location):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Get insight from LLM on given query + graph and save the response\n",
    "\n",
    "    Arguments:\n",
    "        model_name (str): specify the model to be used\n",
    "        query_info (dict): JSON object containing supplemental query information as additional context\n",
    "        output_location (str): path to JSON file where the LLM response should be saved\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Overview:\\n{query_details['overview']}\\n\\nHypothesis:\\n{query_details['hypothesis']}\\n\\nRequest:\\nThe attached graph shows how life insurance mortality actual vs expected ratios (based on amount) are trending from 2012 to 2019 across various segments. I've also provided a data dictionary to help interpret the meaning of the segment and the original rationale for performing the test. Based on the graph and provided context, identify several new insights regarding the presence of a trend (or lack of a trend) and speculate on reasons why we might be seeing a higher or lower than expected mortality for various segments. Also comment on the hypothesis presented.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": make_prompt_with_data_dict_and_sample(prompt, DATA_DICTIONARY_PATH)\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_to_base64(query_details['graph_data_path'])}\"\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(OPENROUTER_URL, headers=HEADERS, json=payload)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API request when generating LLM's insights on graph: {e}\")\n",
    "        return None\n",
    "    with open(output_location, \"w\") as f:\n",
    "        json.dump(response.json(), f, indent=4)\n",
    "    return response.json()\n",
    "\n",
    "def get_all_interpretations(model_name, result_file, output_file):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Get all insight from LLM on graphs and saves results\n",
    "    Arguments:\n",
    "        result_file (str): path to JSON file with query information + graph location\n",
    "        output_file (str): path to JSON file to save query information + LLM insights\n",
    "    \"\"\"\n",
    "    with open(result_file, \"r\") as f:\n",
    "        all_query_details = json.load(f)\n",
    "    final_results = []\n",
    "    for query_detail in all_query_details:\n",
    "        if query_detail[\"graph_status\"] == \"Success\":\n",
    "            curr_timestamp = datetime.datetime.now().isoformat()[:-7]\n",
    "            random_file_name = f\"insight_{curr_timestamp.replace(':', '')}.json\"\n",
    "            insight_obj = get_llm_graph_insights(model_name, query_detail, random_file_name)\n",
    "        else:\n",
    "            insight_obj = None\n",
    "        if insight_obj is None:\n",
    "            query_detail[\"insight_status\"] = \"Failure\"\n",
    "        else:\n",
    "            query_detail[\"insight_status\"] = \"Success\"\n",
    "            query_detail[\"insight_file\"] = random_file_name\n",
    "            query_detail[\"insight\"] = insight_obj[\"choices\"][0][\"message\"][\"content\"]\n",
    "        final_results.append(query_detail)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "    return final_results\n",
    "\n",
    "def create_markdown_files(full_details_path, file_prefix=\"idea\"):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Create a markdown file for each \"idea\"\n",
    "\n",
    "    Arguments:\n",
    "        full_details_path (str): path to JSON file with query + results information\n",
    "        file_prefix (str): prefix for each markdown file generated\n",
    "    \"\"\"\n",
    "    with open(full_details_path, \"r\") as f:\n",
    "        all_query_details = json.load(f)\n",
    "    for i, query_detail in enumerate(all_query_details):\n",
    "        output_text = \"# \"\n",
    "        output_text += query_detail[\"overview\"] + \"\\n\\n\"\n",
    "        output_text += \"### Hypothesis\\n\" + query_detail[\"hypothesis\"] + \"\\n\\n\"\n",
    "        output_text += \"### Graph\" + \"\\n\" + f\"![Plot of trend]({query_detail['graph_data_path']})\\n\\n\"\n",
    "        output_text += \"### Insight\\n\" + query_detail[\"insight\"] + \"\\n\\n\"\n",
    "        output_text += \"### SQL Code:\\n\"\n",
    "        output_text += \"```\" + query_detail[\"sql_code\"] + \"```\"\n",
    "        with open(f\"{file_prefix}_{i+1}.md\", \"w\") as f:\n",
    "            f.write(output_text)\n",
    "    return output_text\n",
    "\n",
    "res = get_initial_ideas(\"google/gemini-3-flash-preview\", \"expected_ideas_structure.json\", \"ideas_log.json\")\n",
    "res2 = get_all_sql_code(\"google/gemini-3-flash-preview\", \"ideas_log.json\", \"sql_structured_output_format.json\", \"all_sql_queries.json\")\n",
    "res3 = query_data(\"all_sql_queries.json\", \"sql_queries_with_results.json\")\n",
    "res4 = get_all_interpretations(\"google/gemini-3-flash-preview\", \"sql_queries_with_results.json\", \"llm_insights.json\")\n",
    "res5 = create_markdown_files(\"llm_insights.json\", \"idea\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
